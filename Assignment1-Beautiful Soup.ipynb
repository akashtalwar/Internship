{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment1- Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "List of all the h1, h2, h3 :\n",
      "h1 Main Page\n",
      "h2 From today's featured article\n",
      "h2 Did you know ...\n",
      "h2 In the news\n",
      "h2 On this day\n",
      "h2 Today's featured picture\n",
      "h2 Other areas of Wikipedia\n",
      "h2 Wikipedia's sister projects\n",
      "h2 Wikipedia languages\n",
      "h2 Navigation menu\n",
      "h3 Personal tools\n",
      "h3 Namespaces\n",
      "h3 Variants\n",
      "h3 Views\n",
      "h3 More\n",
      "h3 Search\n",
      "h3 Navigation\n",
      "h3 Contribute\n",
      "h3 Tools\n",
      "h3 Print/export\n",
      "h3 In other projects\n",
      "h3 Languages\n"
     ]
    }
   ],
   "source": [
    "#Q1.Python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’.\n",
    "\n",
    "page=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "print(page) #To check if data can be extracted form site\n",
    "soup=BeautifulSoup(page.content)\n",
    "#print(soup.prettify) #Function to see organised web page source code\n",
    "print(\"List of all the h1, h2, h3 :\")\n",
    "for heading in soup.find_all([\"h1\", \"h2\", \"h3\"]):\n",
    "    print(heading.name + ' ' + heading.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Inception</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Il buono, il brutto, il cattivo</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Goodfellas</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gisaengchung</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cidade de Deus</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sen to Chihiro no kamikakushi</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>La vita è bella</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Se7en</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seppuku</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Shichinin no samurai</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hamilton</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The Prestige</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Departed</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The Pianist</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>American History X</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Léon</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Nuovo Cinema Paradiso</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Hotaru no haka</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Once Upon a Time in the West</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rear Window</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Modern Times</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>City Lights</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Capharnaüm</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Joker</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Kimi no na wa.</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Coco</td>\n",
       "      <td>8.4</td>\n",
       "      <td>I) (2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Django Unchained</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>WALL·E</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>The Lives of Others</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Oldeuboi</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Memento</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Mononoke-hime</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Once Upon a Time in America</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Raiders of the Lost Ark</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>The Shining</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Apocalypse Now</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Alien</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Tengoku to jigoku</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Dr. Strangelove or: How I Learned to Stop Worr...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Witness for the Prosecution</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Paths of Glory</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Sunset Blvd.</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>The Great Dictator</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Inglourious Basterds</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Requiem for a Dream</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>American Beauty</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Good Will Hunting</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Reservoir Dogs</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Idi i smotri</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Aliens</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Amadeus</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Star Wars: Episode VI - Return of the Jedi</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Das Boot</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2001: A Space Odyssey</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ladri di biciclette</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Movie Name IMDB Rating  \\\n",
       "0                            The Shawshank Redemption         9.3   \n",
       "1                                       The Godfather         9.2   \n",
       "2                                     The Dark Knight         9.0   \n",
       "3                              The Godfather: Part II         9.0   \n",
       "4                                        12 Angry Men         9.0   \n",
       "5       The Lord of the Rings: The Return of the King         8.9   \n",
       "6                                        Pulp Fiction         8.9   \n",
       "7                                    Schindler's List         8.9   \n",
       "8                                           Inception         8.8   \n",
       "9                                          Fight Club         8.8   \n",
       "10  The Lord of the Rings: The Fellowship of the Ring         8.8   \n",
       "11                                       Forrest Gump         8.8   \n",
       "12                    Il buono, il brutto, il cattivo         8.8   \n",
       "13              The Lord of the Rings: The Two Towers         8.7   \n",
       "14                                         The Matrix         8.7   \n",
       "15                                         Goodfellas         8.7   \n",
       "16     Star Wars: Episode V - The Empire Strikes Back         8.7   \n",
       "17                    One Flew Over the Cuckoo's Nest         8.7   \n",
       "18                                       Gisaengchung         8.6   \n",
       "19                                       Interstellar         8.6   \n",
       "20                                     Cidade de Deus         8.6   \n",
       "21                      Sen to Chihiro no kamikakushi         8.6   \n",
       "22                                Saving Private Ryan         8.6   \n",
       "23                                     The Green Mile         8.6   \n",
       "24                                    La vita è bella         8.6   \n",
       "25                                              Se7en         8.6   \n",
       "26                           The Silence of the Lambs         8.6   \n",
       "27                                          Star Wars         8.6   \n",
       "28                                            Seppuku         8.6   \n",
       "29                               Shichinin no samurai         8.6   \n",
       "30                              It's a Wonderful Life         8.6   \n",
       "31                                           Hamilton         8.5   \n",
       "32                                           Whiplash         8.5   \n",
       "33                                   The Intouchables         8.5   \n",
       "34                                       The Prestige         8.5   \n",
       "35                                       The Departed         8.5   \n",
       "36                                        The Pianist         8.5   \n",
       "37                                          Gladiator         8.5   \n",
       "38                                 American History X         8.5   \n",
       "39                                 The Usual Suspects         8.5   \n",
       "40                                               Léon         8.5   \n",
       "41                                      The Lion King         8.5   \n",
       "42                         Terminator 2: Judgment Day         8.5   \n",
       "43                              Nuovo Cinema Paradiso         8.5   \n",
       "44                                     Hotaru no haka         8.5   \n",
       "45                                 Back to the Future         8.5   \n",
       "46                       Once Upon a Time in the West         8.5   \n",
       "47                                             Psycho         8.5   \n",
       "48                                        Rear Window         8.5   \n",
       "49                                         Casablanca         8.5   \n",
       "50                                       Modern Times         8.5   \n",
       "51                                        City Lights         8.5   \n",
       "52                                         Capharnaüm         8.4   \n",
       "53                                              Joker         8.4   \n",
       "54                                     Kimi no na wa.         8.4   \n",
       "55                  Spider-Man: Into the Spider-Verse         8.4   \n",
       "56                                  Avengers: Endgame         8.4   \n",
       "57                             Avengers: Infinity War         8.4   \n",
       "58                                               Coco         8.4   \n",
       "59                                   Django Unchained         8.4   \n",
       "60                              The Dark Knight Rises         8.4   \n",
       "61                                           3 Idiots         8.4   \n",
       "62                                   Taare Zameen Par         8.4   \n",
       "63                                             WALL·E         8.4   \n",
       "64                                The Lives of Others         8.4   \n",
       "65                                           Oldeuboi         8.4   \n",
       "66                                            Memento         8.4   \n",
       "67                                      Mononoke-hime         8.4   \n",
       "68                        Once Upon a Time in America         8.4   \n",
       "69                            Raiders of the Lost Ark         8.4   \n",
       "70                                        The Shining         8.4   \n",
       "71                                     Apocalypse Now         8.4   \n",
       "72                                              Alien         8.4   \n",
       "73                                  Tengoku to jigoku         8.4   \n",
       "74  Dr. Strangelove or: How I Learned to Stop Worr...         8.4   \n",
       "75                        Witness for the Prosecution         8.4   \n",
       "76                                     Paths of Glory         8.4   \n",
       "77                                       Sunset Blvd.         8.4   \n",
       "78                                 The Great Dictator         8.4   \n",
       "79                                             Jagten         8.3   \n",
       "80                               Inglourious Basterds         8.3   \n",
       "81              Eternal Sunshine of the Spotless Mind         8.3   \n",
       "82                                Requiem for a Dream         8.3   \n",
       "83                                    American Beauty         8.3   \n",
       "84                                  Good Will Hunting         8.3   \n",
       "85                                          Toy Story         8.3   \n",
       "86                                         Braveheart         8.3   \n",
       "87                                     Reservoir Dogs         8.3   \n",
       "88                                       Idi i smotri         8.3   \n",
       "89                                             Aliens         8.3   \n",
       "90                                            Amadeus         8.3   \n",
       "91         Star Wars: Episode VI - Return of the Jedi         8.3   \n",
       "92                                           Das Boot         8.3   \n",
       "93                              2001: A Space Odyssey         8.3   \n",
       "94                                 North by Northwest         8.3   \n",
       "95                                            Vertigo         8.3   \n",
       "96                                Singin' in the Rain         8.3   \n",
       "97                                Ladri di biciclette         8.3   \n",
       "98                                       Citizen Kane         8.3   \n",
       "99                  M - Eine Stadt sucht einen Mörder         8.3   \n",
       "\n",
       "   Year of release  \n",
       "0             1994  \n",
       "1             1972  \n",
       "2             2008  \n",
       "3             1974  \n",
       "4             1957  \n",
       "5             2003  \n",
       "6             1994  \n",
       "7             1993  \n",
       "8             2010  \n",
       "9             1999  \n",
       "10            2001  \n",
       "11            1994  \n",
       "12            1966  \n",
       "13            2002  \n",
       "14            1999  \n",
       "15            1990  \n",
       "16            1980  \n",
       "17            1975  \n",
       "18            2019  \n",
       "19            2014  \n",
       "20            2002  \n",
       "21            2001  \n",
       "22            1998  \n",
       "23            1999  \n",
       "24            1997  \n",
       "25            1995  \n",
       "26            1991  \n",
       "27            1977  \n",
       "28            1962  \n",
       "29            1954  \n",
       "30            1946  \n",
       "31            2020  \n",
       "32            2014  \n",
       "33            2011  \n",
       "34            2006  \n",
       "35            2006  \n",
       "36            2002  \n",
       "37            2000  \n",
       "38            1998  \n",
       "39            1995  \n",
       "40            1994  \n",
       "41            1994  \n",
       "42            1991  \n",
       "43            1988  \n",
       "44            1988  \n",
       "45            1985  \n",
       "46            1968  \n",
       "47            1960  \n",
       "48            1954  \n",
       "49            1942  \n",
       "50            1936  \n",
       "51            1931  \n",
       "52            2018  \n",
       "53            2019  \n",
       "54            2016  \n",
       "55            2018  \n",
       "56            2019  \n",
       "57            2018  \n",
       "58        I) (2017  \n",
       "59            2012  \n",
       "60            2012  \n",
       "61            2009  \n",
       "62            2007  \n",
       "63            2008  \n",
       "64            2006  \n",
       "65            2003  \n",
       "66            2000  \n",
       "67            1997  \n",
       "68            1984  \n",
       "69            1981  \n",
       "70            1980  \n",
       "71            1979  \n",
       "72            1979  \n",
       "73            1963  \n",
       "74            1964  \n",
       "75            1957  \n",
       "76            1957  \n",
       "77            1950  \n",
       "78            1940  \n",
       "79            2012  \n",
       "80            2009  \n",
       "81            2004  \n",
       "82            2000  \n",
       "83            1999  \n",
       "84            1997  \n",
       "85            1995  \n",
       "86            1995  \n",
       "87            1992  \n",
       "88            1985  \n",
       "89            1986  \n",
       "90            1984  \n",
       "91            1983  \n",
       "92            1981  \n",
       "93            1968  \n",
       "94            1959  \n",
       "95            1958  \n",
       "96            1952  \n",
       "97            1948  \n",
       "98            1941  \n",
       "99            1931  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2.Python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame.\n",
    "#User Defined Function\n",
    "def extract_data(url):\n",
    "    page=requests.get(url) \n",
    "    #print(page)\n",
    "    soup=BeautifulSoup(page.text,'lxml') \n",
    "\n",
    "    #Extract movie name\n",
    "    header=soup.find_all('h3',class_=\"lister-item-header\")\n",
    "    movie_name=[] #Empty list for storage\n",
    "    for movie_title in header: # Loop to access the list/more text elements\n",
    "        for j in movie_title.find_all(\"a\"):\n",
    "            movie_name.append(j.text.replace(\"\\n\",\" \"))   \n",
    "        \n",
    "    #Extract year of release\n",
    "    header=soup.find_all('h3',class_=\"lister-item-header\")\n",
    "    yor=[] #Empty list for storage\n",
    "    for year in header:\n",
    "        release_year = year.find(class_=\"lister-item-year\")\n",
    "        yor.append(release_year.get_text().strip(\"()\"))\n",
    "    \n",
    "    #Extract Ratings\n",
    "    header1=soup.find_all('div',class_=\"inline-block ratings-imdb-rating\")\n",
    "    ratings=[]\n",
    "    for rating in header1:\n",
    "        for j in rating.find_all(\"strong\"):\n",
    "            ratings.append(j.text)\n",
    "    \n",
    "    #print(movie_name,len(movie_name))\n",
    "    #print(yor,len(yor))\n",
    "    #print(ratings,len(ratings))\n",
    "    data={\"Movie Name\":movie_name,\"IMDB Rating\":ratings,\"Year of release\":yor}\n",
    "    return (data)\n",
    "\n",
    "#Call function:\n",
    "#Url\n",
    "movie_1to50=\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&ref_=adv_prv\"\n",
    "movie_51to100=\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&start=51&ref_=adv_nxt\"\n",
    "\n",
    "data1=pd.DataFrame(extract_data(movie_1to50))\n",
    "data2=pd.DataFrame(extract_data(movie_51to100))\n",
    "data1=data1.append(data2,ignore_index=True)\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drishyam 2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natsamrat</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kireedam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manichitrathazhu</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>96</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Black Friday</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Thevar Magan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kumbalangi Nights</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Visaaranai</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ratsasan</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jersey</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thalapathi</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Soorarai Pottru</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dangal</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Devasuram</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Asuran</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Aparajito</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Kaithi</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Jaane Bhi Do Yaaro</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pyaasa</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Guide</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Peranbu</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Vada Chennai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Thani Oruvan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Kannathil Muthamittal</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Chupke Chupke</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Spadikam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Iruvar</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Vikram Vedha</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Agent Sai Srinivasa Athreya</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Aruvi</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Super Deluxe</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tumbbad</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mahanati</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Khosla Ka Ghosla!</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Anand</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Pudhu Pettai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Premam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Kaakkaa Muttai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Anniyan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Andhadhun</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Bangalore Days</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Mudhalvan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Papanasam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Dhuruvangal Pathinaaru</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Satya</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Shahid</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Soodhu Kavvum</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Jigarthanda</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Pithamagan</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Sairat</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Paan Singh Tomar</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Bhaag Milkha Bhaag</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Talvar</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Hera Pheri</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Swades: We, the People</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Black</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Sholay</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Nil Battey Sannata</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Ustad Hotel</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Chak De! India</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Charulata</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Jo Jeeta Wohi Sikandar</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Mughal-E-Azam</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Zindagi Na Milegi Dobara</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Maheshinte Prathikaaram</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Article 15</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Udaan</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>A Wednesday</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Queen</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Theeran adhigaaram ondru</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Masaan</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Munna Bhai M.B.B.S.</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Alai Payuthey</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Sarfarosh</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Roja</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Baasha</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>OMG: Oh My God!</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Lagaan: Once Upon a Time in India</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Kahaani</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Andaz Apna Apna</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Chhichhore</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Virumandi</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PK</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Iqbal</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Lucia</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Movie Name IMDB Rating Year of release\n",
       "0                      Pather Panchali         8.5            1955\n",
       "1                              Nayakan         8.5            1987\n",
       "2                           Anbe Sivam         8.5            2003\n",
       "3                    Pariyerum Perumal         8.5            2018\n",
       "4                           Drishyam 2         8.5            2021\n",
       "5                              Golmaal         8.5            1979\n",
       "6                          Apur Sansar         8.5            1959\n",
       "7                    C/o Kancharapalem         8.5            2018\n",
       "8                            Natsamrat         8.4            2016\n",
       "9                             Kireedam         8.4            1989\n",
       "10                    Manichitrathazhu         8.4            1993\n",
       "11                                  96         8.4            2018\n",
       "12                        Black Friday         8.4            2004\n",
       "13                        Thevar Magan         8.4            1992\n",
       "14                   Kumbalangi Nights         8.4            2019\n",
       "15                            3 Idiots         8.3            2009\n",
       "16                          Visaaranai         8.3            2015\n",
       "17                    Taare Zameen Par         8.3            2007\n",
       "18                            Ratsasan         8.3            2018\n",
       "19                              Jersey         8.3            2019\n",
       "20                          Thalapathi         8.3            1991\n",
       "21                     Soorarai Pottru         8.3            2020\n",
       "22                              Dangal         8.3            2016\n",
       "23                           Devasuram         8.3            1993\n",
       "24                              Asuran         8.3            2019\n",
       "25                           Aparajito         8.3            1956\n",
       "26                              Kaithi         8.3            2019\n",
       "27                  Jaane Bhi Do Yaaro         8.3            1983\n",
       "28                              Pyaasa         8.3            1957\n",
       "29                               Guide         8.3            1965\n",
       "30                             Peranbu         8.3            2018\n",
       "31                        Vada Chennai         8.2            2018\n",
       "32                        Thani Oruvan         8.2            2015\n",
       "33               Kannathil Muthamittal         8.2            2002\n",
       "34                       Chupke Chupke         8.2            1975\n",
       "35                            Spadikam         8.2            1995\n",
       "36                              Iruvar         8.2            1997\n",
       "37                        Vikram Vedha         8.2            2017\n",
       "38                            Drishyam         8.2            2013\n",
       "39         Agent Sai Srinivasa Athreya         8.2            2019\n",
       "40                               Aruvi         8.2            2016\n",
       "41                        Super Deluxe         8.2            2019\n",
       "42                             Tumbbad         8.2            2018\n",
       "43                            Mahanati         8.2            2018\n",
       "44                   Khosla Ka Ghosla!         8.2            2006\n",
       "45                               Anand         8.2            1971\n",
       "46                        Pudhu Pettai         8.2            2006\n",
       "47                              Premam         8.2            2015\n",
       "48                      Kaakkaa Muttai         8.2            2014\n",
       "49                             Anniyan         8.2            2005\n",
       "50                           Andhadhun         8.2            2018\n",
       "51                      Bangalore Days         8.2            2014\n",
       "52                           Mudhalvan         8.2            1999\n",
       "53                           Papanasam         8.2            2015\n",
       "54              Dhuruvangal Pathinaaru         8.2            2016\n",
       "55                               Satya         8.2            1998\n",
       "56                              Shahid         8.2            2012\n",
       "57                       Soodhu Kavvum         8.2            2013\n",
       "58                         Jigarthanda         8.1            2014\n",
       "59                          Pithamagan         8.1            2003\n",
       "60                  Gangs of Wasseypur         8.1            2012\n",
       "61                              Sairat         8.1            2016\n",
       "62                    Paan Singh Tomar         8.1            2012\n",
       "63                  Bhaag Milkha Bhaag         8.1            2013\n",
       "64                              Talvar         8.1            2015\n",
       "65                          Hera Pheri         8.1            2000\n",
       "66              Swades: We, the People         8.1            2004\n",
       "67                               Black         8.1            2005\n",
       "68                              Sholay         8.1            1975\n",
       "69                  Nil Battey Sannata         8.1            2015\n",
       "70                         Ustad Hotel         8.1            2012\n",
       "71                      Chak De! India         8.1            2007\n",
       "72                           Charulata         8.1            1964\n",
       "73              Jo Jeeta Wohi Sikandar         8.1            1992\n",
       "74                            Drishyam         8.1            2015\n",
       "75                       Mughal-E-Azam         8.1            1960\n",
       "76            Zindagi Na Milegi Dobara         8.1            2011\n",
       "77             Maheshinte Prathikaaram         8.1            2016\n",
       "78                          Article 15         8.1            2019\n",
       "79                               Udaan         8.1            2010\n",
       "80                         A Wednesday         8.1            2008\n",
       "81                               Queen         8.1            2013\n",
       "82            Theeran adhigaaram ondru         8.1            2017\n",
       "83                              Masaan         8.1            2015\n",
       "84                 Munna Bhai M.B.B.S.         8.1            2003\n",
       "85                       Alai Payuthey         8.1            2000\n",
       "86                           Sarfarosh         8.1            1999\n",
       "87                                Roja         8.1            1992\n",
       "88                      Dil Chahta Hai         8.1            2001\n",
       "89                              Baasha         8.1            1995\n",
       "90                     OMG: Oh My God!         8.1            2012\n",
       "91                     Rang De Basanti         8.1            2006\n",
       "92   Lagaan: Once Upon a Time in India         8.1            2001\n",
       "93                             Kahaani         8.1            2012\n",
       "94                     Andaz Apna Apna         8.1            1994\n",
       "95            Uri: The Surgical Strike         8.1            2018\n",
       "96                          Chhichhore         8.1            2019\n",
       "97                           Virumandi         8.1            2004\n",
       "98                                  PK         8.1            2014\n",
       "99                               Iqbal         8.1            2005\n",
       "100                              Lucia         8.1            2013"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3. Python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) \n",
    "#& make data frame.\n",
    "\n",
    "#User-defined function:\n",
    "def extract_data(url):\n",
    "    page=requests.get(url) \n",
    "    #print(page)\n",
    "    soup=BeautifulSoup(page.text,'lxml') \n",
    "\n",
    "    #Extract movie name\n",
    "    header=soup.find_all('td',class_=\"titleColumn\")\n",
    "    movie_name=[] #Empty list for storage\n",
    "    for movie_title in header: # Loop to access the list/more text elements\n",
    "        for j in movie_title.find_all(\"a\"):\n",
    "            movie_name.append(j.text.replace(\"\\n\",\" \"))   \n",
    "        \n",
    "    #Extract year of release\n",
    "    header=soup.find_all('td',class_=\"titleColumn\")\n",
    "    yor=[] #Empty list for storage\n",
    "    for year in header:\n",
    "        release_year = year.find(class_=\"secondaryInfo\")\n",
    "        yor.append(release_year.get_text().strip(\"()\"))\n",
    "    \n",
    "    #Extract Ratings\n",
    "    header1=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "    ratings=[]\n",
    "    for rating in header1:\n",
    "        for j in rating.find_all(\"strong\"):\n",
    "            ratings.append(j.text)\n",
    "    \n",
    "    #print(movie_name,len(movie_name))\n",
    "    #print(yor,len(yor))\n",
    "    #print(ratings,len(ratings))\n",
    "    data={\"Movie Name\":movie_name,\"IMDB Rating\":ratings,\"Year of release\":yor}\n",
    "    return (data)\n",
    "\n",
    "#Call function:\n",
    "#Url\n",
    "movie_list=\"https://www.imdb.com/india/top-rated-indian-movies/\"\n",
    "data1=pd.DataFrame(extract_data(movie_list))\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "data1.loc[0:100,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Book Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>★ Instructions for Dancing</td>\n",
       "      <td>Nicola Yoon</td>\n",
       "      <td>YA / YA Fiction</td>\n",
       "      <td>Book ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Fly</td>\n",
       "      <td>Jonathan Balcombe</td>\n",
       "      <td>Nonfiction / Science &amp; Nature / Animals</td>\n",
       "      <td>Book ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Lights of Prague</td>\n",
       "      <td>Nicole Jarvis</td>\n",
       "      <td>Science Fiction &amp; Fantasy / Fantasy / Historic...</td>\n",
       "      <td>Book ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You People</td>\n",
       "      <td>Nikita Lalwani</td>\n",
       "      <td>Fiction / Literary Fiction</td>\n",
       "      <td>Book ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>★ Ship in a Bottle</td>\n",
       "      <td>Andrew Prahin</td>\n",
       "      <td>Children's / Children's Picture Book</td>\n",
       "      <td>Book ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Book Name        Author Name  \\\n",
       "0   ★ Instructions for Dancing        Nicola Yoon   \n",
       "1                    Super Fly  Jonathan Balcombe   \n",
       "2         The Lights of Prague      Nicole Jarvis   \n",
       "3                   You People     Nikita Lalwani   \n",
       "4           ★ Ship in a Bottle      Andrew Prahin   \n",
       "\n",
       "                                               Genre  \\\n",
       "0                                    YA / YA Fiction   \n",
       "1            Nonfiction / Science & Nature / Animals   \n",
       "2  Science Fiction & Fantasy / Fantasy / Historic...   \n",
       "3                         Fiction / Literary Fiction   \n",
       "4               Children's / Children's Picture Book   \n",
       "\n",
       "                                         Book Review  \n",
       "0                                           Book ...  \n",
       "1                                           Book ...  \n",
       "2                                           Book ...  \n",
       "3                                           Book ...  \n",
       "4                                           Book ...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4.Python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’\n",
    "\n",
    "#User-defined function:\n",
    "#Function returns book name,author name,genre.\n",
    "def extract_data(url):\n",
    "    page=requests.get(url) \n",
    "    #print(page)\n",
    "    soup=BeautifulSoup(page.text,'lxml') \n",
    "\n",
    "    #Extract book name\n",
    "    header=soup.find_all('h4',class_=\"italic\")\n",
    "    book_name=[] #Empty list for storage\n",
    "    for book_title in header: # Loop to access the list/more text elements\n",
    "        for j in book_title.find_all(\"a\"):\n",
    "            book_name.append(j.text.replace(\"\\n\",\" \"))   \n",
    "        \n",
    "    #Extract author name\n",
    "    header=soup.find_all('div',class_=\"flex-article-content\")\n",
    "    aut_name=[] \n",
    "    for author in header:\n",
    "        name=author.find(\"p\",class_=\"sans bold\")\n",
    "        aut_name.append(name.text.replace(\"\\n\",\"\"))\n",
    "                \n",
    "    #Extract Genre\n",
    "    header=soup.find_all('div',class_=\"flex-article-content\")\n",
    "    genre=[] #Skip this step as list hold first 50 movie names\n",
    "    for i in header:\n",
    "        name=i.find(\"p\",class_=\"genre-links hidden-phone\")\n",
    "        genre.append(name.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "    data={\"Book Name\":book_name,\"Author Name\":aut_name,\"Genre\":genre}\n",
    "    return (data)\n",
    "\n",
    "#User defined finction to extract book review\n",
    "def book_review(book):\n",
    "    page=requests.get(book)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    header=soup.find_all('div',class_=\"article-body\")\n",
    "    review=[] #Skip this step as list hold first 50 movie names\n",
    "    for i in header:\n",
    "        for j in i.find_all(\"p\"):\n",
    "            review.append(j.text.replace(\"\\n\",\"\"))\n",
    "            data={\"Book Review\":review}           \n",
    "    return data\n",
    "\n",
    "#Call function:\n",
    "\n",
    "#Top 5 book\n",
    "book_list=\"https://bookpage.com/reviews\"\n",
    "book=pd.DataFrame()\n",
    "data=pd.DataFrame(extract_data(book_list))\n",
    "book=book.append(data,ignore_index=True)\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "top5_book=book.loc[0:4,:]\n",
    "\n",
    "#Top 5 book reviews\n",
    "#Url\n",
    "book1=\"https://bookpage.com/reviews/26325-nicola-yoon-instructions-dancing-ya#.YKy1W74zbIU\"\n",
    "book2=\"https://bookpage.com/reviews/26310-jonathan-balcombe-super-fly-nonfiction#.YKy1iL4zbIU\"\n",
    "book3=\"https://bookpage.com/reviews/26355-nicole-jarvis-lights-prague-science-fiction-fantasy#.YKy1sL4zbIU\"\n",
    "book4=\"https://bookpage.com/reviews/26296-nikita-lalwani-you-people-fiction#.YKy17L4zbIU\"\n",
    "book5=\"https://bookpage.com/reviews/26317-andrew-prahin-ship-bottle-childrens#.YKy2EL4zbIU\"\n",
    "\n",
    "#Call function\n",
    "data1= pd.DataFrame(book_review(book1))\n",
    "data2= pd.DataFrame(book_review(book2))\n",
    "data3= pd.DataFrame(book_review(book3))\n",
    "data4= pd.DataFrame(book_review(book4))\n",
    "data5= pd.DataFrame(book_review(book5))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "top5_book[\"Book Review\"]= [data1,data2,data3,data4,data5]\n",
    "top5_book\n",
    "# Required Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Book Review\n",
      "0                                                   \n",
      "1  Evie used to believe in love. She has bookshel...\n",
      "2  When Evie tries to get rid of her romance nove...\n",
      "3  Nicola Yoon’s Instructions for Dancing will br...\n",
      "4  Excellently developed secondary characters add...\n",
      "5  Yoon delivers this captivating story of first ...\n",
      "                                         Book Review\n",
      "0                                                   \n",
      "1  Without flies, there would be no chocolate. Bi...\n",
      "2  These pollination revelations are just a few a...\n",
      "3  Balcombe hopes readers will consider “the rang...\n",
      "4  The author, who’s written four previous popula...\n",
      "5  But Balcombe is quite serious about flies’ imp...\n",
      "                                         Book Review\n",
      "0                                                   \n",
      "1  Nicole Jarvis’ debut fantasy, The Lights of Pr...\n",
      "2  Set in 19th-century Prague, Jarvis’ careful an...\n",
      "3  The two protagonists’ paths cross and uncross ...\n",
      "4  The story unfolds at a measured pace, submergi...\n",
      "                                         Book Review\n",
      "0                                                   \n",
      "1  The incident that gives You People its title o...\n",
      "2  By this point in the novel, we know quite a bi...\n",
      "3  Born in India and raised in Wales, author Niki...\n",
      "4  Lalwani’s novel takes the reader under the ski...\n",
      "                                         Book Review\n",
      "0                                                   \n",
      "1  Poor Mouse. She lives with Cat, and needless t...\n",
      "2  One day, Mouse takes her living situation into...\n",
      "3  Prahin masters the story’s execution on every ...\n",
      "4  Mouse’s persistence pays off in more ways than...\n"
     ]
    }
   ],
   "source": [
    "#Check column content in column \"Book review\" are with respect to book title\n",
    "print(top5_book[\"Book Review\"][0])\n",
    "print(top5_book[\"Book Review\"][1])\n",
    "print(top5_book[\"Book Review\"][2])\n",
    "print(top5_book[\"Book Review\"][3])\n",
    "print(top5_book[\"Book Review\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New ZealandNZ', 'AustraliaAUS', 'IndiaIND', 'EnglandENG', 'South AfricaSA', 'PakistanPAK', 'BangladeshBAN', 'West IndiesWI', 'Sri LankaSL', 'AfghanistanAFG']\n",
      "['17', '25', '29', '27', '20', '24', '25', '27', '22', '17']\n",
      "['2,054', '2,945', '3,344', '3,100', '2,137', '2,323', '2,286', '2,222', '1,692', '1,054']\n",
      "['121', '118', '115', '115', '107', '97', '91', '82', '77', '62']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New ZealandNZ</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AustraliaAUS</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IndiaIND</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EnglandENG</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South AfricaSA</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PakistanPAK</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BangladeshBAN</td>\n",
       "      <td>25</td>\n",
       "      <td>2,286</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West IndiesWI</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri LankaSL</td>\n",
       "      <td>22</td>\n",
       "      <td>1,692</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AfghanistanAFG</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team Matches Points Ratings\n",
       "0   New ZealandNZ      17  2,054     121\n",
       "1    AustraliaAUS      25  2,945     118\n",
       "2        IndiaIND      29  3,344     115\n",
       "3      EnglandENG      27  3,100     115\n",
       "4  South AfricaSA      20  2,137     107\n",
       "5     PakistanPAK      24  2,323      97\n",
       "6   BangladeshBAN      25  2,286      91\n",
       "7   West IndiesWI      27  2,222      82\n",
       "8     Sri LankaSL      22  1,692      77\n",
       "9  AfghanistanAFG      17  1,054      62"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5.Python program to scrape cricket rankings from ‘www.icc-cricket.com’.\n",
    "# i)Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\") \n",
    "soup=BeautifulSoup(page.content) \n",
    "\n",
    "#Extract team name\n",
    "header=soup.find_all('td',class_=\"rankings-block__banner--team-name\")\n",
    "team_name=[] \n",
    "for i in header:\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "team_name\n",
    "header=soup.find_all('td',class_=\"table-body__cell rankings-table__team\")\n",
    "for i in header:\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "#Consolidated team name\n",
    "final_team=team_name[0:10]\n",
    "print(final_team)\n",
    "\n",
    "#Extract matches\n",
    "#Match for rank=1\n",
    "header=soup.find_all('td',class_=\"rankings-block__banner--matches\")\n",
    "match=[] \n",
    "for i in header:\n",
    "    match.append(i.text)\n",
    "\n",
    "#Points for rank=1\n",
    "header=soup.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "point=[] \n",
    "for i in header:\n",
    "    point.append(i.text)\n",
    "\n",
    "#Rating for rank=1\n",
    "header=soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "rating=[] \n",
    "for i in header:\n",
    "    rating.append(i.text.replace(\"\\n\",\"\").strip())\n",
    "\n",
    "#Matches & Points for rank>1\n",
    "header=soup.find_all('td',class_=\"table-body__cell u-center-text\")\n",
    "matches=[]\n",
    "for i in header:\n",
    "    matches.append(i.text)\n",
    "\n",
    "#Ratings for rank>1\n",
    "header=soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "ratings=[]\n",
    "for i in header:\n",
    "    ratings.append(i.text)\n",
    "\n",
    "#Consolidated match list\n",
    "final_match=matches[0:18:2]\n",
    "match=match+final_match\n",
    "print(match)\n",
    "#Consolidated points\n",
    "final_points=matches[1:19:2]\n",
    "point=point+final_points\n",
    "print(point)\n",
    "#Consolidated ratings\n",
    "rating=rating+ratings[0:9]\n",
    "print(rating)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df[\"Team\"]=final_team\n",
    "df[\"Matches\"]=match\n",
    "df[\"Points\"]=point\n",
    "df[\"Ratings\"]=rating\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name Country Rating\n",
       "0           Babar Azam     PAK    865\n",
       "1          Virat Kohli     IND    857\n",
       "2         Rohit Sharma     IND    825\n",
       "3          Ross Taylor      NZ    801\n",
       "4          Aaron Finch     AUS    791\n",
       "5       Jonny Bairstow     ENG    785\n",
       "6         Fakhar Zaman     PAK    778\n",
       "7  Francois du Plessis      SA    778\n",
       "8         David Warner     AUS    773\n",
       "9            Shai Hope      WI    773"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii)Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\") \n",
    "soup=BeautifulSoup(page.content) \n",
    "\n",
    "#Extract team name\n",
    "header=soup.find_all('div',class_=\"rankings-block__banner--name\")\n",
    "name=[] \n",
    "for i in header:\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "header=soup.find_all('td',class_=\"table-body__cell name\")\n",
    "names=[] \n",
    "for i in header:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        names.append(j.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "#Consolidate names\n",
    "final_names=[]\n",
    "a=name[0:1]\n",
    "b=names[0:9]\n",
    "final_names = a+b\n",
    "final_names\n",
    "\n",
    "#Rank1 country & rating\n",
    "country=[]\n",
    "header=soup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "for i in header:\n",
    "    country.append(i.text.replace(\"\\n\",\"\").split())\n",
    "\n",
    "c=pd.Series(data=country)\n",
    "f=c[0]+c[1]\n",
    "county=f[0:1]\n",
    "rating0=f[1:2]\n",
    "\n",
    "#Country 2nd liist\n",
    "country=[]\n",
    "header=soup.find_all('td',class_=\"table-body__cell nationality-logo\")\n",
    "for i in header:\n",
    "    country.append(i.text.replace(\"\\n\",\"\"))\n",
    "country1=country[0:9]\n",
    "country1\n",
    "\n",
    "#Rating 2nd liist\n",
    "rating=[]\n",
    "header=soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "for i in header:\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating1=rating[0:9]\n",
    "rating1\n",
    "\n",
    "#Consolidate country list\n",
    "final_country=county+country1\n",
    "\n",
    "#Consolidate rating list\n",
    "final_rating=rating0+rating1\n",
    "\n",
    "\n",
    "player=pd.DataFrame()\n",
    "player[\"Name\"]=final_names\n",
    "player[\"Country\"]=final_country\n",
    "player[\"Rating\"]=final_rating\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name Country Rating\n",
       "0        Trent Boult      NZ    737\n",
       "1       Mehedi Hasan     BAN    725\n",
       "2   Mujeeb Ur Rahman     AFG    708\n",
       "3         Matt Henry      NZ    691\n",
       "4     Jasprit Bumrah     IND    690\n",
       "5      Kagiso Rabada      SA    666\n",
       "6       Chris Woakes     ENG    665\n",
       "7     Josh Hazlewood     AUS    660\n",
       "8  Mustafizur Rahman     BAN    652\n",
       "9        Pat Cummins     AUS    646"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "#Extract bowler name\n",
    "header=soup.find_all('div',class_=\"rankings-block__banner--name\")\n",
    "name=[] \n",
    "for i in header:\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "name1=name[1:2]\n",
    "\n",
    "header=soup.find_all('td',class_=\"table-body__cell name\")\n",
    "names=[] \n",
    "for i in header:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        names.append(j.text.replace(\"\\n\",\"\"))\n",
    "#Consolidate name\n",
    "name2=names[9:18]\n",
    "final_names= name1 + name2\n",
    "final_names\n",
    "\n",
    "#Rank-1 country & rating\n",
    "country=[]\n",
    "header=soup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "for i in header:\n",
    "    country.append(i.text.replace(\"\\n\",\"\").split())\n",
    "country[1]\n",
    "c=pd.Series(data=country)\n",
    "\n",
    "f=c[0]+c[1]\n",
    "county=f[2:3]\n",
    "rating0=f[3:4]\n",
    "\n",
    "\n",
    "#Country names rank>1\n",
    "country=[]\n",
    "header=soup.find_all('td',class_=\"table-body__cell nationality-logo\")\n",
    "for i in header:\n",
    "    country.append(i.text.replace(\"\\n\",\"\"))\n",
    "country[9:18]\n",
    "country2=country[9:18]\n",
    "\n",
    "#Consolidated country\n",
    "final_country=county+country2\n",
    "final_country\n",
    "\n",
    "#Rating 2nd list bowler\n",
    "rating=[]\n",
    "header=soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "for i in header:\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating1=rating[9:18]\n",
    "rating1\n",
    "#Consolidated bowler list\n",
    "final_rating=rating0+rating1\n",
    "final_rating\n",
    "\n",
    "bowler=pd.DataFrame()\n",
    "bowler[\"Name\"]=final_names\n",
    "bowler[\"Country\"]=final_country\n",
    "bowler[\"Rating\"]=final_rating\n",
    "bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AustraliaAUS', 'South AfricaSA', 'EnglandENG', 'IndiaIND', 'New ZealandNZ', 'West IndiesWI', 'PakistanPAK', 'BangladeshBAN', 'Sri LankaSL', 'IrelandIRE']\n",
      "['18', '24', '17', '20', '21', '12', '15', '5', '11', '2']\n",
      "['2,955', '2,828', '1,993', '2,226', '1,947', '1,025', '1,101', '306', '519', '25']\n",
      "['164', '118', '117', '111', '93', '85', '73', '61', '47', '13']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AustraliaAUS</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South AfricaSA</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EnglandENG</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiaIND</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New ZealandNZ</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West IndiesWI</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PakistanPAK</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BangladeshBAN</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri LankaSL</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IrelandIRE</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team Matches Points Ratings\n",
       "0    AustraliaAUS      18  2,955     164\n",
       "1  South AfricaSA      24  2,828     118\n",
       "2      EnglandENG      17  1,993     117\n",
       "3        IndiaIND      20  2,226     111\n",
       "4   New ZealandNZ      21  1,947      93\n",
       "5   West IndiesWI      12  1,025      85\n",
       "6     PakistanPAK      15  1,101      73\n",
       "7   BangladeshBAN       5    306      61\n",
       "8     Sri LankaSL      11    519      47\n",
       "9      IrelandIRE       2     25      13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6. Python program to scrape cricket rankings from ‘www.icc-cricket.com’.\n",
    "# i)Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\") \n",
    "soup=BeautifulSoup(page.content) \n",
    "\n",
    "#Extract team name\n",
    "header=soup.find_all('td',class_=\"rankings-block__banner--team-name\")\n",
    "team_name=[] \n",
    "for i in header:\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "team_name\n",
    "header=soup.find_all('td',class_=\"table-body__cell rankings-table__team\")\n",
    "for i in header:\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "#Consolidated team name\n",
    "final_team=team_name[0:10]\n",
    "print(final_team)\n",
    "\n",
    "#Extract matches\n",
    "#Match for rank=1\n",
    "header=soup.find_all('td',class_=\"rankings-block__banner--matches\")\n",
    "match=[] \n",
    "for i in header:\n",
    "    match.append(i.text)\n",
    "\n",
    "#Points for rank=1\n",
    "header=soup.find_all('td',class_=\"rankings-block__banner--points\")\n",
    "point=[] \n",
    "for i in header:\n",
    "    point.append(i.text)\n",
    "\n",
    "#Rating for rank=1\n",
    "header=soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "rating=[] \n",
    "for i in header:\n",
    "    rating.append(i.text.replace(\"\\n\",\"\").strip())\n",
    "\n",
    "#Matches & Points for rank>1\n",
    "header=soup.find_all('td',class_=\"table-body__cell u-center-text\")\n",
    "matches=[]\n",
    "for i in header:\n",
    "    matches.append(i.text)\n",
    "\n",
    "#Ratings for rank>1\n",
    "header=soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "ratings=[]\n",
    "for i in header:\n",
    "    ratings.append(i.text)\n",
    "\n",
    "#Consolidated match list\n",
    "final_match=matches[0:18:2]\n",
    "match=match+final_match\n",
    "print(match)\n",
    "#Consolidated points\n",
    "final_points=matches[1:19:2]\n",
    "point=point+final_points\n",
    "print(point)\n",
    "#Consolidated ratings\n",
    "rating=rating+ratings[0:9]\n",
    "print(rating)\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df[\"Team\"]=final_team\n",
    "df[\"Matches\"]=match\n",
    "df[\"Points\"]=point\n",
    "df[\"Ratings\"]=rating\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name Country Rating\n",
       "0     Tammy Beaumont     ENG    765\n",
       "1        Lizelle Lee      SA    758\n",
       "2       Alyssa Healy     AUS    756\n",
       "3    Stafanie Taylor      WI    746\n",
       "4        Meg Lanning     AUS    723\n",
       "5  Amy Satterthwaite      NZ    715\n",
       "6    Smriti Mandhana     IND    710\n",
       "7        Mithali Raj     IND    709\n",
       "8     Natalie Sciver     ENG    685\n",
       "9    Laura Wolvaardt      SA    683"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii)Top 10 ODI Batsmen in women along with the records of their team and rating.\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\") \n",
    "soup=BeautifulSoup(page.content) \n",
    "\n",
    "#Extract team name\n",
    "header=soup.find_all('div',class_=\"rankings-block__banner--name\")\n",
    "name=[] \n",
    "for i in header:\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "header=soup.find_all('td',class_=\"table-body__cell name\")\n",
    "names=[] \n",
    "for i in header:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        names.append(j.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "#Consolidate names\n",
    "final_names=[]\n",
    "a=name[0:1]\n",
    "b=names[0:9]\n",
    "final_names = a+b\n",
    "final_names\n",
    "\n",
    "#Rank1 country & rating\n",
    "country=[]\n",
    "header=soup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "for i in header:\n",
    "    country.append(i.text.replace(\"\\n\",\"\").split())\n",
    "\n",
    "c=pd.Series(data=country)\n",
    "f=c[0]+c[1]\n",
    "county=f[0:1]\n",
    "rating0=f[1:2]\n",
    "\n",
    "#Country 2nd liist\n",
    "country=[]\n",
    "header=soup.find_all('td',class_=\"table-body__cell nationality-logo\")\n",
    "for i in header:\n",
    "    country.append(i.text.replace(\"\\n\",\"\"))\n",
    "country1=country[0:9]\n",
    "country1\n",
    "\n",
    "#Rating 2nd liist\n",
    "rating=[]\n",
    "header=soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "for i in header:\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating1=rating[0:9]\n",
    "rating1\n",
    "\n",
    "#Consolidate country list\n",
    "final_country=county+country1\n",
    "\n",
    "#Consolidate rating list\n",
    "final_rating=rating0+rating1\n",
    "\n",
    "\n",
    "player=pd.DataFrame()\n",
    "player[\"Name\"]=final_names\n",
    "player[\"Country\"]=final_country\n",
    "player[\"Rating\"]=final_rating\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name Country Rating\n",
       "0    Marizanne Kapp      SA    418\n",
       "1      Ellyse Perry     AUS    418\n",
       "2   Stafanie Taylor      WI    410\n",
       "3    Natalie Sciver     ENG    349\n",
       "4     Deepti Sharma     IND    343\n",
       "5     Jess Jonassen     AUS    307\n",
       "6  Ashleigh Gardner     AUS    252\n",
       "7  Dane van Niekerk      SA    243\n",
       "8     Sophie Devine      NZ    242\n",
       "9       Amelia Kerr      NZ    236"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii)Top 10 ODI all-rounder in women along with the records of their team and rating.\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\") \n",
    "soup=BeautifulSoup(page.content) \n",
    "\n",
    "#Extract team name\n",
    "header=soup.find_all('div',class_=\"rankings-block__banner--name\")\n",
    "name=[] \n",
    "for i in header:\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "header=soup.find_all('td',class_=\"table-body__cell name\")\n",
    "names=[] \n",
    "for i in header:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        names.append(j.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "#Consolidate names\n",
    "final_names=[]\n",
    "a=name[2:3]\n",
    "b=names[18:27]\n",
    "final_names = a+b\n",
    "final_names\n",
    "\n",
    "#Rank1 country & rating\n",
    "country=[]\n",
    "header=soup.find_all('div',class_=\"rankings-block__banner--nationality\")\n",
    "for i in header:\n",
    "    country.append(i.text.replace(\"\\n\",\"\").split())\n",
    "\n",
    "c=pd.Series(data=country)\n",
    "f=c[0]+c[1]+c[2]\n",
    "county=f[4:5]\n",
    "rating0=f[5:6]\n",
    "\n",
    "#Country 2nd liist\n",
    "country=[]\n",
    "header=soup.find_all('td',class_=\"table-body__cell nationality-logo\")\n",
    "for i in header:\n",
    "    country.append(i.text.replace(\"\\n\",\"\"))\n",
    "country1=country[18:27]\n",
    "country1\n",
    "\n",
    "#Rating 2nd liist\n",
    "rating=[]\n",
    "header=soup.find_all('td',class_=\"table-body__cell u-text-right rating\")\n",
    "for i in header:\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating1=rating[18:27]\n",
    "rating1\n",
    "\n",
    "#Consolidate country list\n",
    "final_country=county+country1\n",
    "\n",
    "#Consolidate rating list\n",
    "final_rating=rating0+rating1\n",
    "\n",
    "\n",
    "player=pd.DataFrame()\n",
    "player[\"Name\"]=final_names\n",
    "player[\"Country\"]=final_country\n",
    "player[\"Rating\"]=final_rating\n",
    "player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [503]>\n"
     ]
    }
   ],
   "source": [
    "# Q7.Python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. \n",
    "#The scraped data should include Product Name, Price, Image URL and Average Rating.\n",
    "page=requests.get(\"https://www.amazon.in/mobile-phones/b/?ie=UTF8&node=1389401031&ref_=nav_cs_mobiles_9292c6cb7b394d30b2467b8f631090a7\") \n",
    "print(page)\n",
    "soup=BeautifulSoup(page.content) \n",
    "\n",
    "#Unable to scrape due to website error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today</td>\n",
       "      <td>Mostly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>High: 65 °F</td>\n",
       "      <td>Sunny, with a high near 65. Breezy, with a wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Partly Cloudyand Breezythen MostlyCloudy</td>\n",
       "      <td>Low: 52 °F</td>\n",
       "      <td>Increasing clouds, with a low around 52. Breez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Mostly Cloudythen MostlySunny andBreezy</td>\n",
       "      <td>High: 64 °F</td>\n",
       "      <td>Cloudy through mid morning, then gradual clear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WednesdayNight</td>\n",
       "      <td>Mostly Clearand Breezythen PartlyCloudy</td>\n",
       "      <td>Low: 53 °F</td>\n",
       "      <td>Partly cloudy, with a low around 53. Breezy, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Mostly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>High: 66 °F</td>\n",
       "      <td>Mostly sunny, with a high near 66. Breezy, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ThursdayNight</td>\n",
       "      <td>Mostly Clearand Breezythen PartlyCloudy</td>\n",
       "      <td>Low: 54 °F</td>\n",
       "      <td>Mostly clear, with a low around 54. Breezy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>High: 66 °F</td>\n",
       "      <td>Mostly sunny, with a high near 66.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FridayNight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Low: 52 °F</td>\n",
       "      <td>Mostly clear, with a low around 52.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High: 68 °F</td>\n",
       "      <td>Sunny, with a high near 68.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Period                         Short Description  Temperature  \\\n",
       "0           Today          Mostly Sunnythen Sunnyand Breezy  High: 65 °F   \n",
       "1         Tonight  Partly Cloudyand Breezythen MostlyCloudy   Low: 52 °F   \n",
       "2       Wednesday   Mostly Cloudythen MostlySunny andBreezy  High: 64 °F   \n",
       "3  WednesdayNight   Mostly Clearand Breezythen PartlyCloudy   Low: 53 °F   \n",
       "4        Thursday          Mostly Sunnythen Sunnyand Breezy  High: 66 °F   \n",
       "5   ThursdayNight   Mostly Clearand Breezythen PartlyCloudy   Low: 54 °F   \n",
       "6          Friday                              Mostly Sunny  High: 66 °F   \n",
       "7     FridayNight                              Mostly Clear   Low: 52 °F   \n",
       "8        Saturday                                     Sunny  High: 68 °F   \n",
       "\n",
       "                                         Description  \n",
       "0  Sunny, with a high near 65. Breezy, with a wes...  \n",
       "1  Increasing clouds, with a low around 52. Breez...  \n",
       "2  Cloudy through mid morning, then gradual clear...  \n",
       "3  Partly cloudy, with a low around 53. Breezy, w...  \n",
       "4  Mostly sunny, with a high near 66. Breezy, wit...  \n",
       "5       Mostly clear, with a low around 54. Breezy.   \n",
       "6                 Mostly sunny, with a high near 66.  \n",
       "7                Mostly clear, with a low around 52.  \n",
       "8                        Sunny, with a high near 68.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8.Python program to extract information about the local weather from the National Weather Service website of USA, \n",
    "#https://www.weather.gov/ for the city, San Francisco. \n",
    "#You need to extract data about 7 day extended forecast display for the city. \n",
    "#The data should include period, short description, temperature and description.\n",
    "page=requests.get(\"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YLYcfL4zbIU\") \n",
    "print(page)\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Extract Period\n",
    "header=soup.find_all('p',class_=\"period-name\")\n",
    "period=[] \n",
    "for i in header:\n",
    "    period.append(i.text)\n",
    "    \n",
    "#Extract short description\n",
    "header=soup.find_all('p',class_=\"short-desc\")\n",
    "sdesc=[] \n",
    "for i in header:\n",
    "    sdesc.append(i.text)\n",
    "    \n",
    "#Extract temperature high\n",
    "header=soup.find_all('p',class_=\"temp temp-high\")\n",
    "th=[] \n",
    "for i in header:\n",
    "    th.append(i.text)\n",
    "\n",
    "#Extract temperature low\n",
    "header=soup.find_all('p',class_=\"temp temp-low\")\n",
    "tl=[] \n",
    "for i in header:\n",
    "    tl.append(i.text)\n",
    "temp=[th[0],tl[0],th[1],tl[1],th[2],tl[2],th[3],tl[3],th[4]]\n",
    "\n",
    "#Extract Description\n",
    "header=soup.find_all('div',class_=\"col-sm-10 forecast-text\")\n",
    "des=[] \n",
    "for i in header:\n",
    "    des.append(i.text)\n",
    "ld=des[0:9]\n",
    "    \n",
    "weather=pd.DataFrame()\n",
    "weather[\"Period\"]=period\n",
    "weather[\"Short Description\"]=sdesc\n",
    "weather[\"Temperature\"]=temp\n",
    "weather[\"Description\"]=ld\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Start date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Wondermail</td>\n",
       "      <td>[4 - 7 LPA]</td>\n",
       "      <td>[1 Jul' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Stack Developer (MERN)</td>\n",
       "      <td>Project Tinker</td>\n",
       "      <td>[4 - 7.2 LPA]</td>\n",
       "      <td>[1 Jul' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Kaizen Academy</td>\n",
       "      <td>[4.5 - 6 LPA]</td>\n",
       "      <td>[1 Jul' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sales Development Representative</td>\n",
       "      <td>Amigobulls</td>\n",
       "      <td>[5.5 - 6.5 LPA]</td>\n",
       "      <td>[1 Jul' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>Underground Movement LLP</td>\n",
       "      <td>[3 - 5 LPA]</td>\n",
       "      <td>[1 Jul' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Operations Executive</td>\n",
       "      <td>Alphacore Technologies Private Limited</td>\n",
       "      <td>[3 - 3.5 LPA]</td>\n",
       "      <td>[1 Jul' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Ruhcom Enterprises Private Limited</td>\n",
       "      <td>[3 LPA]</td>\n",
       "      <td>[1 Jul' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Admission Counselor (Sales)</td>\n",
       "      <td>Sky Education Group</td>\n",
       "      <td>[3 LPA]</td>\n",
       "      <td>[30 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sales And Business Development Analyst</td>\n",
       "      <td>Mo's F&amp;B Group</td>\n",
       "      <td>[3 - 3.1 LPA]</td>\n",
       "      <td>[30 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Growth Hacking Digital Marketer</td>\n",
       "      <td>Sleep Love</td>\n",
       "      <td>[3 - 3.5 LPA]</td>\n",
       "      <td>[30 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Junior Node.js Developer</td>\n",
       "      <td>Askadmissions.ai</td>\n",
       "      <td>[3 - 4 LPA]</td>\n",
       "      <td>[30 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Junior Digital Marketing Executive</td>\n",
       "      <td>Krivy</td>\n",
       "      <td>[3 LPA]</td>\n",
       "      <td>[30 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>iOS App Developer</td>\n",
       "      <td>Ascentspark Software Private Limited</td>\n",
       "      <td>[3.6 - 7 LPA]</td>\n",
       "      <td>[30 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Food Journalist</td>\n",
       "      <td>Truffle Nation</td>\n",
       "      <td>[3 - 4.5 LPA]</td>\n",
       "      <td>[30 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>Habitate Technologies Private Limited</td>\n",
       "      <td>[5.2 - 7 LPA]</td>\n",
       "      <td>[30 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>SoluLab</td>\n",
       "      <td>[3 - 5 LPA]</td>\n",
       "      <td>[28 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>SoluLab</td>\n",
       "      <td>[3 - 4.2 LPA]</td>\n",
       "      <td>[28 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Associate Full Stack Developer</td>\n",
       "      <td>REPOZITORY TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>[3 - 3.6 LPA]</td>\n",
       "      <td>[30 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>Beehive Academy India</td>\n",
       "      <td>[4.2 - 8.2 LPA]</td>\n",
       "      <td>[28 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Product Marketer</td>\n",
       "      <td>Bip</td>\n",
       "      <td>[3 - 6 LPA]</td>\n",
       "      <td>[27 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Tabeazy</td>\n",
       "      <td>[3 LPA]</td>\n",
       "      <td>[27 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Associate - Business Development</td>\n",
       "      <td>Leverage Edu</td>\n",
       "      <td>[3.6 LPA]</td>\n",
       "      <td>[27 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Research Analyst (Economics)</td>\n",
       "      <td>DEX-DEFT Research And Consulting OPC Private L...</td>\n",
       "      <td>[3 LPA]</td>\n",
       "      <td>[30 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>AIMonk Labs Technology Limited</td>\n",
       "      <td>[5 - 6.5 LPA]</td>\n",
       "      <td>[27 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Kasper Consulting Private Limited</td>\n",
       "      <td>[3.25 - 4 LPA]</td>\n",
       "      <td>[26 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Business Development Executive (Inside Sales)</td>\n",
       "      <td>GREedge</td>\n",
       "      <td>[3.75 LPA]</td>\n",
       "      <td>[26 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>PEPKIDZ LEARNING</td>\n",
       "      <td>[3 - 4 LPA]</td>\n",
       "      <td>[25 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Full Stack Software Engineer</td>\n",
       "      <td>Flair Labs</td>\n",
       "      <td>[3 - 4 LPA]</td>\n",
       "      <td>[25 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Associate Front End Developer</td>\n",
       "      <td>Little Big Things</td>\n",
       "      <td>[3 - 5 LPA]</td>\n",
       "      <td>[25 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Talent Acquisition Executive</td>\n",
       "      <td>CrewKarma</td>\n",
       "      <td>[3 - 5 LPA]</td>\n",
       "      <td>[24 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Codfirm</td>\n",
       "      <td>[5 - 8 LPA]</td>\n",
       "      <td>[24 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Backend Developer</td>\n",
       "      <td>WebMOBI</td>\n",
       "      <td>[3 LPA]</td>\n",
       "      <td>[24 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>TMBill Software</td>\n",
       "      <td>[3 LPA]</td>\n",
       "      <td>[24 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Junior Sales Associate</td>\n",
       "      <td>Kraftshala</td>\n",
       "      <td>[4 LPA]</td>\n",
       "      <td>[24 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Digital Marketing Specialist</td>\n",
       "      <td>Black Jack</td>\n",
       "      <td>[3 - 5 LPA]</td>\n",
       "      <td>[24 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Android App Developer</td>\n",
       "      <td>Storlyy</td>\n",
       "      <td>[3 - 3.5 LPA]</td>\n",
       "      <td>[23 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Softsensor.ai</td>\n",
       "      <td>[4 - 8 LPA]</td>\n",
       "      <td>[24 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Junior Software Developer</td>\n",
       "      <td>ZoryBoard Software Solutions</td>\n",
       "      <td>[3 - 4 LPA]</td>\n",
       "      <td>[20 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>SNet Labs Private Limited</td>\n",
       "      <td>[3 - 3.2 LPA]</td>\n",
       "      <td>[20 Jun' 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>[3.3 - 4 LPA]</td>\n",
       "      <td>[20 Jun' 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job Title  \\\n",
       "0                            Full Stack Developer   \n",
       "1                     Full Stack Developer (MERN)   \n",
       "2                  Business Development Executive   \n",
       "3                Sales Development Representative   \n",
       "4                                Graphic Designer   \n",
       "5                            Operations Executive   \n",
       "6                  Business Development Executive   \n",
       "7                     Admission Counselor (Sales)   \n",
       "8          Sales And Business Development Analyst   \n",
       "9                 Growth Hacking Digital Marketer   \n",
       "10                       Junior Node.js Developer   \n",
       "11             Junior Digital Marketing Executive   \n",
       "12                              iOS App Developer   \n",
       "13                                Food Journalist   \n",
       "14                      Junior Software Developer   \n",
       "15                           Full Stack Developer   \n",
       "16                               Business Analyst   \n",
       "17                 Associate Full Stack Developer   \n",
       "18                            Full Stack Engineer   \n",
       "19                               Product Marketer   \n",
       "20                 Business Development Executive   \n",
       "21               Associate - Business Development   \n",
       "22                   Research Analyst (Economics)   \n",
       "23                      Machine Learning Engineer   \n",
       "24                               Business Analyst   \n",
       "25  Business Development Executive (Inside Sales)   \n",
       "26                 Business Development Associate   \n",
       "27                   Full Stack Software Engineer   \n",
       "28                  Associate Front End Developer   \n",
       "29                   Talent Acquisition Executive   \n",
       "30                           Full Stack Developer   \n",
       "31                              Backend Developer   \n",
       "32                           Full Stack Developer   \n",
       "33                         Junior Sales Associate   \n",
       "34                   Digital Marketing Specialist   \n",
       "35                          Android App Developer   \n",
       "36                       Associate Data Scientist   \n",
       "37                      Junior Software Developer   \n",
       "38                   Associate Software Developer   \n",
       "39                           Full Stack Developer   \n",
       "\n",
       "                                              Company              CTC  \\\n",
       "0                                          Wondermail      [4 - 7 LPA]   \n",
       "1                                      Project Tinker    [4 - 7.2 LPA]   \n",
       "2                                      Kaizen Academy    [4.5 - 6 LPA]   \n",
       "3                                          Amigobulls  [5.5 - 6.5 LPA]   \n",
       "4                            Underground Movement LLP      [3 - 5 LPA]   \n",
       "5              Alphacore Technologies Private Limited    [3 - 3.5 LPA]   \n",
       "6                  Ruhcom Enterprises Private Limited          [3 LPA]   \n",
       "7                                 Sky Education Group          [3 LPA]   \n",
       "8                                      Mo's F&B Group    [3 - 3.1 LPA]   \n",
       "9                                          Sleep Love    [3 - 3.5 LPA]   \n",
       "10                                   Askadmissions.ai      [3 - 4 LPA]   \n",
       "11                                              Krivy          [3 LPA]   \n",
       "12               Ascentspark Software Private Limited    [3.6 - 7 LPA]   \n",
       "13                                     Truffle Nation    [3 - 4.5 LPA]   \n",
       "14              Habitate Technologies Private Limited    [5.2 - 7 LPA]   \n",
       "15                                            SoluLab      [3 - 5 LPA]   \n",
       "16                                            SoluLab    [3 - 4.2 LPA]   \n",
       "17            REPOZITORY TECHNOLOGIES PRIVATE LIMITED    [3 - 3.6 LPA]   \n",
       "18                              Beehive Academy India  [4.2 - 8.2 LPA]   \n",
       "19                                                Bip      [3 - 6 LPA]   \n",
       "20                                            Tabeazy          [3 LPA]   \n",
       "21                                       Leverage Edu        [3.6 LPA]   \n",
       "22  DEX-DEFT Research And Consulting OPC Private L...          [3 LPA]   \n",
       "23                     AIMonk Labs Technology Limited    [5 - 6.5 LPA]   \n",
       "24                  Kasper Consulting Private Limited   [3.25 - 4 LPA]   \n",
       "25                                            GREedge       [3.75 LPA]   \n",
       "26                                   PEPKIDZ LEARNING      [3 - 4 LPA]   \n",
       "27                                         Flair Labs      [3 - 4 LPA]   \n",
       "28                                  Little Big Things      [3 - 5 LPA]   \n",
       "29                                          CrewKarma      [3 - 5 LPA]   \n",
       "30                                            Codfirm      [5 - 8 LPA]   \n",
       "31                                            WebMOBI          [3 LPA]   \n",
       "32                                    TMBill Software          [3 LPA]   \n",
       "33                                         Kraftshala          [4 LPA]   \n",
       "34                                         Black Jack      [3 - 5 LPA]   \n",
       "35                                            Storlyy    [3 - 3.5 LPA]   \n",
       "36                                      Softsensor.ai      [4 - 8 LPA]   \n",
       "37                       ZoryBoard Software Solutions      [3 - 4 LPA]   \n",
       "38                          SNet Labs Private Limited    [3 - 3.2 LPA]   \n",
       "39    RavGins International Private Limited (Wobb.ai)    [3.3 - 4 LPA]   \n",
       "\n",
       "      Start date  \n",
       "0    [1 Jul' 21]  \n",
       "1    [1 Jul' 21]  \n",
       "2    [1 Jul' 21]  \n",
       "3    [1 Jul' 21]  \n",
       "4    [1 Jul' 21]  \n",
       "5    [1 Jul' 21]  \n",
       "6    [1 Jul' 21]  \n",
       "7   [30 Jun' 21]  \n",
       "8   [30 Jun' 21]  \n",
       "9   [30 Jun' 21]  \n",
       "10  [30 Jun' 21]  \n",
       "11  [30 Jun' 21]  \n",
       "12  [30 Jun' 21]  \n",
       "13  [30 Jun' 21]  \n",
       "14  [30 Jun' 21]  \n",
       "15  [28 Jun' 21]  \n",
       "16  [28 Jun' 21]  \n",
       "17  [30 Jun' 21]  \n",
       "18  [28 Jun' 21]  \n",
       "19  [27 Jun' 21]  \n",
       "20  [27 Jun' 21]  \n",
       "21  [27 Jun' 21]  \n",
       "22  [30 Jun' 21]  \n",
       "23  [27 Jun' 21]  \n",
       "24  [26 Jun' 21]  \n",
       "25  [26 Jun' 21]  \n",
       "26  [25 Jun' 21]  \n",
       "27  [25 Jun' 21]  \n",
       "28  [25 Jun' 21]  \n",
       "29  [24 Jun' 21]  \n",
       "30  [24 Jun' 21]  \n",
       "31  [24 Jun' 21]  \n",
       "32  [24 Jun' 21]  \n",
       "33  [24 Jun' 21]  \n",
       "34  [24 Jun' 21]  \n",
       "35  [23 Jun' 21]  \n",
       "36  [24 Jun' 21]  \n",
       "37  [20 Jun' 21]  \n",
       "38  [20 Jun' 21]  \n",
       "39  [20 Jun' 21]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9. Python program to scrape fresher job listings from ‘https://internshala.com/’. \n",
    "#It should include job title, company name, CTC, and apply date.\n",
    "page=requests.get(\"https://internshala.com/fresher-jobs\") \n",
    "print(page)\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Extract Job Title\n",
    "header=soup.find_all('div',class_=\"heading_4_5 profile\")\n",
    "jt=[] \n",
    "for i in header:\n",
    "    jt.append(i.text.strip())\n",
    "\n",
    "#Extract Company\n",
    "header=soup.find_all('a',class_=\"link_display_like_text\")\n",
    "company=[] \n",
    "for i in header:\n",
    "    company.append(i.text.strip())\n",
    "\n",
    "#Extract CTC & Join date\n",
    "header=soup.find_all('div',class_=\"item_body\")\n",
    "ctc=[] \n",
    "for i in header:\n",
    "    ctc.append(i.text.strip())\n",
    "\n",
    "#Remove string by nan\n",
    "for i in range(0,len(ctc)):\n",
    "    if ctc[i]=='Starts\\xa0Immediately':\n",
    "        ctc[i]=np.nan\n",
    "\n",
    "#COnvert to dataframe & remove NaN values\n",
    "df=pd.DataFrame()\n",
    "df[\"CTC\"]=ctc\n",
    "df.dropna(axis=0,inplace=True)\n",
    "\n",
    "#Convert dataframe to list\n",
    "dfn=df.values.tolist()\n",
    "\n",
    "job=pd.DataFrame()\n",
    "job[\"Job Title\"]=jt\n",
    "job[\"Company\"]=company\n",
    "job[\"CTC\"]=dfn[0:80:2]\n",
    "job[\"Start date\"]=dfn[1:80:2]\n",
    "job"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
